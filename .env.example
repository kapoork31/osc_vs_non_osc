# Azure Subscription Variables
SUBSCRIPTION_ID = ''
LOCATION = 'westeurope'
TENANT_ID = ''
BASE_NAME = ''
SP_APP_ID = ''
SP_APP_SECRET = ''
RESOUCE_GROUP = 'mlops-rg'

# Mock build/release ID for local testing
BUILD_BUILDID = '001'

# Azure ML Workspace Variables
WORKSPACE_NAME = 'aml-workspace'
EXPERIMENT_NAME = ''

# AML Compute Cluster Config
AML_ENV_NAME='osc__vs_nonosc_training_env'
AML_COMPUTE_CLUSTER_NAME = 'train-cluster'
AML_COMPUTE_CLUSTER_CPU_SKU = 'STANDARD_DS2_V2'
AML_CLUSTER_MAX_NODES = '4'
AML_CLUSTER_MIN_NODES = '0'
AML_CLUSTER_PRIORITY = 'lowpriority'
# Training Config
MODEL_NAME = 'osc__vs_nonosc_model'
AUTOENCODER_NAME = 'data_drift_model'
MODEL_VERSION = '1'
TRAIN_SCRIPT_PATH = 'training/train.py'
# AML Pipeline Config
TRAINING_PIPELINE_NAME = 'Training Pipeline'
SCORING_PIPELINE_NAME = 'Scoring Pipeline'
MODEL_PATH = ''
EVALUATE_SCRIPT_PATH = 'evaluate/evaluate_model.py'
REGISTER_SCRIPT_PATH = 'register/register_model.py'
SCORING_SCRIPT_PATH = 'scoring/score_pipeline_script.py'
SCORING_SCRIPT_OUTPUT_PATH = 'output_data_predicted_temp'
SCORING_SCRIPT_INPUT_META = 'data_to_predict_meta_temp'
SCORING_SCRIPT_INPUT_RAW = 'data_to_predict_raw_temp'
SOURCES_DIR_TRAIN = 'osc__vs_nonosc'
DATASET_NAME = 'fizzyo_breath_data'
DATASET_VERSION = 'latest'
# Optional. Set it if you have configured non default datastore to point to your data
DATASTORE_NAME = ''
SCORE_SCRIPT = 'scoring/score.py'

# Optional. Used by a training pipeline with R on Databricks
DB_CLUSTER_ID = ''

# Optional. Container Image name for image creation
IMAGE_NAME = 'mltrained'

# Run Evaluation Step in AML pipeline
RUN_EVALUATION = 'true'

# Set to true cancels the Azure ML pipeline run when evaluation criteria are not met.
ALLOW_RUN_CANCEL = 'true'

# Flag to allow rebuilding the AML Environment after it was built for the first time. This enables dependency updates from conda_dependencies.yaml.
AML_REBUILD_ENVIRONMENT = 'false'
